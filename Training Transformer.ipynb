{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import all of the used libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import spacy\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchtext.data import Field, BucketIterator, TabularDataset\n",
    "from Utlis import calculate_bleu, saveCheckpoint, loadCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a field and vocab to split and tokenize the articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 1609\n",
      "Number of validation examples: 344\n",
      "Number of testing examples: 345\n",
      "Unique tokens in source vocabulary: 10004\n"
     ]
    }
   ],
   "source": [
    "# Define the Fields for tokenization\n",
    "articles = Field(tokenize=\"spacy\", tokenizer_language=\"en_core_web_sm\", init_token=\"<sos>\", eos_token=\"<eos>\")\n",
    "\n",
    "# Define the fields dictionary for the TabularDataset\n",
    "fields = {\"article\": (\"src\", articles), \"highlights\": (\"trg\", articles)}\n",
    "\n",
    "# Path to your data file\n",
    "data_path = \"Datasets/cnn_dailymail/test.csv\"\n",
    "\n",
    "# Create the TabularDataset\n",
    "dataset = TabularDataset(\n",
    "    path=data_path,\n",
    "    format=\"csv\",  \n",
    "    fields=fields\n",
    ")\n",
    "\n",
    "\n",
    "tinyDataset, _ = dataset.split(split_ratio=[0.2, 0.8])\n",
    "\n",
    "# Split the dataset into training, validation, and test sets\n",
    "trainData, validData, testData = tinyDataset.split(split_ratio=[0.7, 0.15, 0.15])\n",
    "\n",
    "# Build the vocabulary for the Fields\n",
    "articles.build_vocab(trainData, max_size=10000, min_freq=2)\n",
    "\n",
    "# Print some statistics\n",
    "print(f\"Number of training examples: {len(trainData.examples)}\")\n",
    "print(f\"Number of validation examples: {len(validData.examples)}\")\n",
    "print(f\"Number of testing examples: {len(testData.examples)}\")\n",
    "print(f\"Unique tokens in source vocabulary: {len(articles.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "articles = torch.load(\"Vocab/Field.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forget Swansea , Stoke City and West Ham , the top seven would be seriously challenged by ' Team Pardew ' should this manager have had a full season in charge at one club . That is after Crystal Palace , managed by Alan Pardew , beat Manchester City 2 - 1 at Selhurst Park on Monday night , the English manager 's ninth win   in South London since leaving his role at Newcastle at the end of December . His former club have since plummeted in the Premier League while Palace now find themselves threatening the top half , and combining his records at both clubs this season would see ' Team Pardew ' sit in eighth place , just five points behind Southampton . Alan Pardew could be a candidate for manager of the year with his record at Newcastle and Crystal Palace . The Premier League table with Team Pardew in - as well as a team complied from pre / post Pardew results . Newcastle fans were calling for Pardew 's head for many years , seen as owner Mike Ashley 's puppet , and were sitting in 10th place when the 53 - year - old returned ' home ' to Crystal Palace . The Eagles were in the relegation zone along with Burnley and Leicester City , struggling to pick up points following Neil Warnock 's sacking . But while John Carver has picked up just nine points in his 12 games in charge at St James ' Park , Pardew 's Palace now have 39 points and are comfortably above the drop zone . A team compiled with Newcastle and Crystal Palace 's stats pre / post Pardew would be sitting in 19th ( albeit with 22 Premier League clubs now technically involved ) . A top - half finish is now the aim for Pardew and his men , as Toon supporters still fear relegation following a 1 - 0 derby defeat to Sunderland on Easter Sunday . Pardew celebrates with his Newcastle team and Moussa SIssoko after his goal against QPR in November . Newcastle fans hold a banner calling the removal of Pardew in a Premier League game at Stoke in September . John Carver 's Toon side are not safe from relegation yet after a 1 - 0 defeat at the hands of Sunderland . It all started with a 4 - 0 win at Dover Athletic in the FA Cup and now Crystal Palace have won four in five , most recently beating the champions . His stock will continue to rise with this table , which would put him just six points adrift of Liverpool in fifth . Pardew has recently insisted he would perform at a top club , better than Monday 's counterpart Manuel Pellegrini at least , while he is definitely a contender for Premier League Manager of the Year award . And nobody would have predicted that in 2014 . Glenn Murray celebrates after netting the opening goal during Crystal Palace 's victory over Manchester City .\n"
     ]
    }
   ],
   "source": [
    "exampleArticle = \" \".join(vars(trainData.examples[0])['src'])\n",
    "print(exampleArticle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, \n",
    "                 embeddingSize,\n",
    "                 sourceVocabSize,\n",
    "                 targetVocabSize,\n",
    "                 sourcePadIndex,\n",
    "                 numberHeads,\n",
    "                 numberEncoderLayers,\n",
    "                 numberDecoderLayers,\n",
    "                 forwardExpansion,\n",
    "                 dropout,\n",
    "                 maxLength,\n",
    "                 device\n",
    "                ) -> None:\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        # Creating a map to turn words into vectors, similar to Word2Vec\n",
    "        self.sourceWordEmbedding = nn.Embedding(sourceVocabSize, embeddingSize)\n",
    "        \n",
    "        # Creating a map to turn the position of the word into a vec\n",
    "        self.sourcePositionEmbedding = nn.Embedding(maxLength, embeddingSize)\n",
    "        \n",
    "        # Same same, but for the target, (Need to double check to see if this needed as both the text are in english)\n",
    "        self.targetWordEmbedding = nn.Embedding(targetVocabSize, embeddingSize)\n",
    "        self.targetPositionEmbedding = nn.Embedding(maxLength, embeddingSize)\n",
    "        \n",
    "        # Set the device, GPU or CPU\n",
    "        self.device = device\n",
    "        \n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=embeddingSize,\n",
    "            nhead=numberHeads,\n",
    "            num_encoder_layers=numberEncoderLayers,\n",
    "            num_decoder_layers=numberDecoderLayers,\n",
    "            dim_feedforward=forwardExpansion,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        # Create a Linear and softmax function to turn word vectors into words\n",
    "        self.fcOut = nn.Linear(embeddingSize, targetVocabSize)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.sourcePadIdx = sourcePadIndex\n",
    "        \n",
    "    def getSourceMask(self, src):\n",
    "        # We are changing the shape of the mask from (srcLen, N) -> (N, srcLen)\n",
    "        # it needed to be in this format for pytorch to use it :)\n",
    "        sourceMask = src.transpose(0, 1) == self.sourcePadIdx\n",
    "        \n",
    "        return sourceMask\n",
    "    \n",
    "    def forward(self, source, target):\n",
    "        # Handle 1-dimensional tensor (vector) case\n",
    "        sourceSeqLength, N, = source.shape[0],source.shape[1]\n",
    "        targetSeqLength, N, = target.shape[0],target.shape[1]\n",
    "        \n",
    "        # Creating the positions used for the position embeddings\n",
    "        sourcePositions = (\n",
    "            torch.arange(0, sourceSeqLength).unsqueeze(1).expand(sourceSeqLength, N)\n",
    "            .to(self.device)\n",
    "        )\n",
    "\n",
    "        targetPositions = (\n",
    "            torch.arange(0, targetSeqLength).unsqueeze(1).expand(targetSeqLength, N)\n",
    "            .to(self.device)\n",
    "        )\n",
    "        \n",
    "        # We are combining both the word embedding with the position of the words \n",
    "        embedSource = self.dropout(\n",
    "            (self.sourceWordEmbedding(source) + self.sourcePositionEmbedding(sourcePositions))\n",
    "        )\n",
    "        \n",
    "        embedTarget = self.dropout(\n",
    "            (self.targetWordEmbedding(target) + self.targetPositionEmbedding(targetPositions))\n",
    "        )\n",
    "        \n",
    "        # Now we are creating a mask that can be used on all the text\n",
    "        sourcePaddingMask = self.getSourceMask(source)\n",
    "        targetMask = self.transformer.generate_square_subsequent_mask(targetSeqLength).to(self.device)\n",
    "        \n",
    "        out = self.transformer(\n",
    "            embedSource,\n",
    "            embedTarget,\n",
    "            src_key_padding_mask = sourcePaddingMask,\n",
    "            tgt_mask = targetMask\n",
    "        )\n",
    "        \n",
    "        out = self.fcOut(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the article Highlights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHighlights(article, articles_field, model, device):\n",
    "    # Tokenize the article\n",
    "    tokenized_article = articles_field.tokenize(article)\n",
    "    \n",
    "    # Convert tokens to numerical indices\n",
    "    numerical_article = [articles_field.vocab.stoi[token] for token in tokenized_article]\n",
    "    \n",
    "    # Convert to tensor and add batch dimension\n",
    "    numerical_article = torch.LongTensor(numerical_article).unsqueeze(1).to(device)\n",
    "    \n",
    "    # Generate highlights\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Assuming target is not used for generating highlights\n",
    "        target = torch.zeros((numerical_article.shape[0], 1)).long().to(device)\n",
    "        output = model(numerical_article, target)\n",
    "    \n",
    "    # Get the generated highlights as numerical indices\n",
    "    generated_indices = output.argmax(dim=-1)\n",
    "    \n",
    "    # Convert indices to tokens\n",
    "    generated_tokens = [articles_field.vocab.itos[idx] for idx in generated_indices.squeeze()]\n",
    "    \n",
    "    # Remove special tokens and join tokens into a single string\n",
    "    # generated_highlights = ' '.join(token for token in generated_tokens if token not in ['<sos>', '<eos>', '<pad>'])\n",
    "    # generated_highlights = ' '.join(token for token in generated_tokens if token not in ['<pad>'])\n",
    "    \n",
    "    return_tokens = ''\n",
    "    for i in generated_tokens:\n",
    "        if i == '<eos>':\n",
    "            break\n",
    "        if i != '<pad>':\n",
    "            return_tokens += ' ' + i\n",
    "        \n",
    "    return return_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Training parameters    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Training phase\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "loadTheModel = True\n",
    "loadModelFolder = \"P:/New Checkpoints\"\n",
    "saveModel = True\n",
    "\n",
    "# Training hyperparameters\n",
    "numberEpochs = 3000\n",
    "learningRate = 3e-4\n",
    "batchSize = (32, 32, 32)\n",
    "\n",
    "# Model hyperparameters\n",
    "sourceVocabSize, targetVocabSize = len(articles.vocab), len(articles.vocab)\n",
    "embeddingSize = 512\n",
    "numberHeads = 8\n",
    "numberEncoderLayers = 3\n",
    "numberDecoderLayers = 3\n",
    "dropout = 0.10\n",
    "maxLength = 10000\n",
    "forwardExpansion = 4\n",
    "sourcePadIndex = articles.vocab.stoi['<pad>']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model and optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\TensorFlow-GPU\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "# Tensorboard to be fancy\n",
    "writer = SummaryWriter('runs/lossPlot')\n",
    "step = 0\n",
    "\n",
    "trainIterator, validIterator, testIterator = BucketIterator.splits(\n",
    "    (trainData, validData, testData),\n",
    "    batch_sizes=batchSize,\n",
    "    sort_within_batch = True, # Note the reason that you are sorting it is because when you are in batches it wont have to calculate extra padding size\n",
    "    sort_key = lambda x: len(x.src),\n",
    "    device = device\n",
    ")\n",
    "\n",
    "model = Transformer(\n",
    "    embeddingSize=embeddingSize,\n",
    "    sourceVocabSize=sourceVocabSize,\n",
    "    targetVocabSize=targetVocabSize,\n",
    "    sourcePadIndex=sourcePadIndex,\n",
    "    numberHeads=numberHeads,\n",
    "    numberEncoderLayers=numberEncoderLayers,\n",
    "    numberDecoderLayers=numberDecoderLayers,\n",
    "    forwardExpansion=forwardExpansion,\n",
    "    dropout=dropout,\n",
    "    maxLength=maxLength,\n",
    "    device=device\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learningRate)\n",
    "\n",
    "\n",
    "padIndex = articles.vocab.stoi['<pad>']\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = padIndex)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove useless warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress the warning\n",
    "warnings.filterwarnings(\"ignore\", message=\"1Torch was not compiled with flash attention.\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadModel(model, optimizer, filepath):\n",
    "    # epochs = sorted([int(x[5:][:-4]) for x in os.listdir(filepath)])\n",
    "    epochs = sorted([int(x[5:-4]) for x in os.listdir(filepath) if x.endswith(\".pth\")])\n",
    "    print(epochs)\n",
    "    \n",
    "    start = epochs[-1]\n",
    "    \n",
    "    loadCheckpoint(model, optimizer, f'{filepath}/point{start}.pth')\n",
    "    \n",
    "    return start + 1, model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[456]\n",
      "    Checkpoint loaded from 'P:/New Checkpoints/point456.pth'\n",
      "Forget Swansea , Stoke City and West Ham , the top seven would be seriously challenged by ' Team Pardew ' should this manager have had a full season in charge at one club . That is after Crystal Palace , managed by Alan Pardew , beat Manchester City 2 - 1 at Selhurst Park on Monday night , the English manager 's ninth win   in South London since leaving his role at Newcastle at the end of December . His former club have since plummeted in the Premier League while Palace now find themselves threatening the top half , and combining his records at both clubs this season would see ' Team Pardew ' sit in eighth place , just five points behind Southampton . Alan Pardew could be a candidate for manager of the year with his record at Newcastle and Crystal Palace . The Premier League table with Team Pardew in - as well as a team complied from pre / post Pardew results . Newcastle fans were calling for Pardew 's head for many years , seen as owner Mike Ashley 's puppet , and were sitting in 10th place when the 53 - year - old returned ' home ' to Crystal Palace . The Eagles were in the relegation zone along with Burnley and Leicester City , struggling to pick up points following Neil Warnock 's sacking . But while John Carver has picked up just nine points in his 12 games in charge at St James ' Park , Pardew 's Palace now have 39 points and are comfortably above the drop zone . A team compiled with Newcastle and Crystal Palace 's stats pre / post Pardew would be sitting in 19th ( albeit with 22 Premier League clubs now technically involved ) . A top - half finish is now the aim for Pardew and his men , as Toon supporters still fear relegation following a 1 - 0 derby defeat to Sunderland on Easter Sunday . Pardew celebrates with his Newcastle team and Moussa SIssoko after his goal against QPR in November . Newcastle fans hold a banner calling the removal of Pardew in a Premier League game at Stoke in September . John Carver 's Toon side are not safe from relegation yet after a 1 - 0 defeat at the hands of Sunderland . It all started with a 4 - 0 win at Dover Athletic in the FA Cup and now Crystal Palace have won four in five , most recently beating the champions . His stock will continue to rise with this table , which would put him just six points adrift of Liverpool in fifth . Pardew has recently insisted he would perform at a top club , better than Monday 's counterpart Manuel Pellegrini at least , while he is definitely a contender for Premier League Manager of the Year award . And nobody would have predicted that in 2014 . Glenn Murray celebrates after netting the opening goal during Crystal Palace 's victory over Manchester City .\n",
      "Crystal Palace beat Manchester City 2 - 1 at Selhurst Park on Monday . \n",
      " South London side are   11th in Premier League table and look to be safe . \n",
      " Alan Pardew left Newcastle in 10th place when he departed in December . \n",
      " John Carver 's side have only picked up nine points since . \n",
      " ' Team Pardew ' would be eighth in the table five points behind Southampton .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 457 / 3000]: 100%|██████████| 51/51 [01:56<00:00,  2.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Checkpoint saved to 'P:/New Checkpoints/point457.pth'\n",
      "    Key Dot Points: \n",
      "       11th 11th what three three Tyne three left may career three . . . . reduce . killing reduce . what Alan . . paint killing and 1 place what three black and 1 black what reduce and left black and left left left but . place place may side chance and side black place left reduce 3 game and left through left Tyne ceremony nine but place team ' Anfield left regardless United 5 and black may Lord team . Premier cities and high left cities cities denied players place . denied denied cities between Tyne ' cities may ' judge Boyd high cities formed ' Tyne post high statement three arrest vehicles statement ceremony lack ceremony cities cities ceremony high left cities anyone Ferguson nine statement cities ceremony cities black Pennsylvania high Congress statement nine high high left cities Spain high Tyne ceremony when high Tyne Tyne 22 place left high high through formed high high high 2 statement matches Tyne high high cities high through high black high killing style high left high lined 2 Tyne cities left ceremony left cities left high high black cities left cities Out ceremony high team Tyne statement Lord high high left cities high ' cities left statement team black black high high high left cities high cities career cities high statement black style left high high cities cities ' left cities through high United high high high nine cities statement left high black left high Tyne Tyne cities Tyne her left high black 2 cities statement high high black high cities high may high high cities cities high black left cities black Tyne left high Tyne a high black left nine left nine Tyne high high cities high side cities Tyne nine high 4 high cities statement black left three Tyne left left high high left searched high Tyne 2 high ' left cities left high increases cities left black left high left left cities high 2 left statement not black nine cities statement cities high Tyne her high black black high left search left ' vehicles black left high high high high black high high left black cities three left high high high high left left high Tyne cities high three high left £ left vehicles high formed left left cities high ' ' high cities killing left cities Tyne high ' high left may Tyne left left high left left high left black high three statement black cities three Tyne high left left left Tyne cities high cities 4 left high high ' left high when high left statement ' left left statement high cities Tyne a three black career 2 left ' high high black high cities left left high Tyne high ' high high left high nine high black left cities high high Tyne black Tyne left high community left cities left left left high high left Tyne left high left cities high left high high style Tyne high left sexual statement statement left cities Tyne high cities left high high cities through high three left New high left high denied\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 458 / 3000]:  10%|▉         | 5/51 [00:47<07:20,  9.58s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 53\u001b[0m\n\u001b[0;32m     49\u001b[0m     torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     51\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 53\u001b[0m     \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_scalar\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTraining Loss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m     step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# Save the model info\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\TensorFlow-GPU\\lib\\site-packages\\torch\\utils\\tensorboard\\writer.py:393\u001b[0m, in \u001b[0;36mSummaryWriter.add_scalar\u001b[1;34m(self, tag, scalar_value, global_step, walltime, new_style, double_precision)\u001b[0m\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcaffe2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m workspace\n\u001b[0;32m    391\u001b[0m     scalar_value \u001b[38;5;241m=\u001b[39m workspace\u001b[38;5;241m.\u001b[39mFetchBlob(scalar_value)\n\u001b[1;32m--> 393\u001b[0m summary \u001b[38;5;241m=\u001b[39m \u001b[43mscalar\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    394\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscalar_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_style\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_style\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdouble_precision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdouble_precision\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_file_writer()\u001b[38;5;241m.\u001b[39madd_summary(summary, global_step, walltime)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\TensorFlow-GPU\\lib\\site-packages\\torch\\utils\\tensorboard\\summary.py:369\u001b[0m, in \u001b[0;36mscalar\u001b[1;34m(name, tensor, collections, new_style, double_precision)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscalar\u001b[39m(name, tensor, collections\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, new_style\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, double_precision\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    353\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Output a `Summary` protocol buffer containing a single scalar value.\u001b[39;00m\n\u001b[0;32m    354\u001b[0m \n\u001b[0;32m    355\u001b[0m \u001b[38;5;124;03m    The generated Summary has a Tensor.proto containing the input Tensor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;124;03m      ValueError: If tensor has the wrong shape or type.\u001b[39;00m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 369\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m \u001b[43mmake_np\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[0;32m    370\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[0;32m    371\u001b[0m         tensor\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    372\u001b[0m     ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensor should contain one element (0 dimensions). Was given size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor\u001b[38;5;241m.\u001b[39msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dimensions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;66;03m# python float is double precision in numpy\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\TensorFlow-GPU\\lib\\site-packages\\torch\\utils\\tensorboard\\_convert_np.py:23\u001b[0m, in \u001b[0;36mmake_np\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([x])\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_prepare_pytorch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(x)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but numpy array, torch tensor, or caffe2 blob name are expected.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     26\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\TensorFlow-GPU\\lib\\site-packages\\torch\\utils\\tensorboard\\_convert_np.py:32\u001b[0m, in \u001b[0;36m_prepare_pytorch\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mbfloat16:\n\u001b[0;32m     31\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat16)\n\u001b[1;32m---> 32\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train\n",
    "import os, datetime\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "time = str(datetime.datetime.now()).replace(\":\", \" \")\n",
    "\n",
    "\n",
    "if loadTheModel:\n",
    "    start, model, optimizer = loadModel(model, optimizer, loadModelFolder)\n",
    "    fileDir = loadModelFolder\n",
    "else:\n",
    "    start = 0\n",
    "    fileDir = f'Checkpoints/{time}'\n",
    "    os.makedirs(f'Checkpoints/{time}')\n",
    "# sys.exit()\n",
    "    \n",
    "exampleArticle = \"Ever noticed how plane seats appear to be getting smaller and smaller? With increasing numbers of people taking to the skies, some experts are questioning if having such packed out planes is putting passengers at risk. They say that the shrinking space on aeroplanes is not only uncomfortable - it's putting our health and safety in danger. More than squabbling over the arm rest, shrinking space on planes putting our health and safety in danger? This week, a U.S consumer advisory group set up by the Department of Transportation said at a public hearing that while the government is happy to set standards for animals flying on planes, it doesn't stipulate a minimum amount of space for humans. 'In a world where animals have more rights to space and food than humans,' said Charlie Leocha, consumer representative on the committee. 'It is time that the DOT and FAA take a stand for humane treatment of passengers.' But could crowding on planes lead to more serious issues than fighting for space in the overhead lockers, crashing elbows and seat back kicking? Tests conducted by the FAA use planes with a 31 inch pitch, a standard which on some airlines has decreased . Many economy seats on United Airlines have 30 inches of room, while some airlines offer as little as 28 inches . Cynthia Corbertt, a human factors researcher with the Federal Aviation Administration, that it conducts tests on how quickly passengers can leave a plane. But these tests are conducted using planes with 31 inches between each row of seats, a standard which on some airlines has decreased, reported the Detroit News. The distance between two seats from one point on a seat to the same point on the seat behind it is known as the pitch. While most airlines stick to a pitch of 31 inches or above, some fall below this. While United Airlines has 30 inches of space, Gulf Air economy seats have between 29 and 32 inches, Air Asia offers 29 inches and Spirit Airlines offers just 28 inches. British Airways has a seat pitch of 31 inches, while easyJet has 29 inches, Thomson's short haul seat pitch is 28 inches, and Virgin Atlantic's is 30-31.\"\n",
    "example_idx = 0\n",
    "exampleArticle = \" \".join(vars(trainData.examples[example_idx])['src'])\n",
    "print(exampleArticle)\n",
    "exampleHighlight = \" \".join(vars(trainData.examples[example_idx])['trg'])\n",
    "print(exampleHighlight)\n",
    "# \"Experts question if  packed out planes are putting passengers at risk .\n",
    "# \"U.S consumer advisory group says minimum space must be stipulated .\"\n",
    "# \"Safety tests conducted on planes with more leg room than airlines offer .\"\n",
    "for epoch in range(start, numberEpochs):\n",
    "    \n",
    "    # Train the model\n",
    "    model.train()\n",
    "    \n",
    "    for batchIndex, batch in tqdm(enumerate(trainIterator), total=len(trainIterator), desc=f\"[Epoch {epoch} / {numberEpochs}]\"):\n",
    "        inputData = batch.src.to(device)\n",
    "        target = batch.trg.to(device)\n",
    "        \n",
    "        # Shift the target tensor by one time step\n",
    "        target_input = target[:-1, :]\n",
    "        \n",
    "        # forward prop\n",
    "        output = model(inputData, target_input)\n",
    "        \n",
    "        output = output.reshape(-1, output.shape[2])\n",
    "        target_output = target[1:, :].reshape(-1)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss = criterion(output, target_output)\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        writer.add_scalar(\"Training Loss\", loss, global_step=step)\n",
    "        step += 1\n",
    "        \n",
    "    # Save the model info\n",
    "    if saveModel:\n",
    "        checkpoint = {\n",
    "            \"stateDict\" : model.state_dict(),\n",
    "            \"optimizer\" : optimizer.state_dict()\n",
    "        }\n",
    "        \n",
    "        # save the checkpoint\n",
    "        saveCheckpoint(model, optimizer, f'{fileDir}/point{epoch}.pth')\n",
    "        \n",
    "        if epoch % 50 == 0:\n",
    "            for i in range(epoch-49,epoch):\n",
    "                file_path = f'{fileDir}/point{i}.pth'\n",
    "                if os.path.exists(file_path):\n",
    "                    os.remove(file_path)\n",
    "        elif epoch % 50 != 1:\n",
    "            file_path = f'{fileDir}/point{epoch-1}.pth'\n",
    "            if os.path.exists(file_path):\n",
    "                os.remove(file_path)\n",
    "            \n",
    "        \n",
    "    # Give the test output a show\n",
    "    model.eval()\n",
    "    try:\n",
    "        testHighlights = getHighlights(exampleArticle, articles, model, device)\n",
    "\n",
    "        print(f\"    Key Dot Points: \\n      {testHighlights}\")\n",
    "    except:\n",
    "        print(\"    Cant Load Highlights\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = calculate_bleu(testData, model, articles, highlights, device)\n",
    "print(f\"The BLEU score is: {score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
